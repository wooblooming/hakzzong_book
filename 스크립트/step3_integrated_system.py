#!/usr/bin/env python3.11
"""
ê³ ë“±í•™ìƒ íƒêµ¬ì£¼ì œ ë„ì„œ ì¶”ì²œ ì‹œìŠ¤í…œ (í†µí•© ë²„ì „)
- Gemini 2.5 Proë¥¼ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ë„ì„œ ê²€ì¦
- ë„¤ì´ë²„ ë„ì„œ API ì—°ë™
- ìƒì„¸í•œ ì¶”ì²œ ì´ìœ  ìƒì„±
"""

import pandas as pd
import json
import re
import os
from dotenv import load_dotenv
import google.generativeai as genai
from datetime import datetime
import time
import requests
from typing import Dict, List, Tuple, Optional
from collections import Counter

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ìƒëŒ€ ê²½ë¡œ ì§€ì •)
load_dotenv('../ì„¤ì •íŒŒì¼/.env')

class APIUsageTracker:
    """API ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ì¶”ì  í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.usage_log = []
        self.total_cost = 0.0
        
        # Gemini API ê°€ê²© (USD per 1M tokens, 2024ë…„ ê¸°ì¤€)
        self.pricing = {
            'gemini-1.5-flash': {
                'input': 0.075,   # $0.075 per 1M input tokens
                'output': 0.30    # $0.30 per 1M output tokens
            },
            'gemini-1.5-pro': {
                'input': 1.25,    # $1.25 per 1M input tokens
                'output': 5.00    # $5.00 per 1M output tokens
            }
        }
    
    def estimate_tokens(self, text: str) -> int:
        """í…ìŠ¤íŠ¸ì˜ ëŒ€ëµì ì¸ í† í° ìˆ˜ ì¶”ì • (í•œêµ­ì–´ ê¸°ì¤€)"""
        # í•œêµ­ì–´ëŠ” ì•½ 1.5-2 í† í°/ë‹¨ì–´, ì˜ì–´ëŠ” ì•½ 1.3 í† í°/ë‹¨ì–´
        korean_chars = len(re.findall(r'[ê°€-í£]', text))
        other_chars = len(text) - korean_chars
        
        # í•œêµ­ì–´: 2ìë‹¹ 1í† í°, ì˜ì–´/ìˆ«ì: 4ìë‹¹ 1í† í°ìœ¼ë¡œ ê·¼ì‚¬
        estimated_tokens = (korean_chars // 2) + (other_chars // 4)
        return max(estimated_tokens, 1)
    
    def log_api_call(self, model: str, input_text: str, output_text: str, 
                     call_type: str = "general"):
        """API í˜¸ì¶œ ì •ë³´ ë¡œê¹…"""
        input_tokens = self.estimate_tokens(input_text)
        output_tokens = self.estimate_tokens(output_text)
        
        # ë¹„ìš© ê³„ì‚°
        input_cost = (input_tokens / 1_000_000) * self.pricing[model]['input']
        output_cost = (output_tokens / 1_000_000) * self.pricing[model]['output']
        total_cost = input_cost + output_cost
        
        self.total_cost += total_cost
        
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'model': model,
            'call_type': call_type,
            'input_tokens': input_tokens,
            'output_tokens': output_tokens,
            'input_cost_usd': round(input_cost, 6),
            'output_cost_usd': round(output_cost, 6),
            'total_cost_usd': round(total_cost, 6)
        }
        
        self.usage_log.append(log_entry)
        return log_entry
    
    def save_usage_report(self, filename: str = None):
        """ì‚¬ìš©ëŸ‰ ë¦¬í¬íŠ¸ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f'api_usage_report_{timestamp}.txt'
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("Gemini API ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ë¦¬í¬íŠ¸\n")
            f.write("=" * 80 + "\n")
            f.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ì´ API í˜¸ì¶œ ìˆ˜: {len(self.usage_log)}íšŒ\n")
            f.write(f"ì´ ì˜ˆìƒ ë¹„ìš©: ${self.total_cost:.4f} USD (â‚©{self.total_cost * 1300:.0f})\n\n")
            
            # ëª¨ë¸ë³„ í†µê³„
            model_stats = {}
            for log in self.usage_log:
                model = log['model']
                if model not in model_stats:
                    model_stats[model] = {
                        'calls': 0, 'input_tokens': 0, 'output_tokens': 0, 'cost': 0.0
                    }
                model_stats[model]['calls'] += 1
                model_stats[model]['input_tokens'] += log['input_tokens']
                model_stats[model]['output_tokens'] += log['output_tokens']
                model_stats[model]['cost'] += log['total_cost_usd']
            
            f.write("ëª¨ë¸ë³„ ì‚¬ìš© í†µê³„:\n")
            f.write("-" * 50 + "\n")
            for model, stats in model_stats.items():
                f.write(f"{model}:\n")
                f.write(f"  í˜¸ì¶œ ìˆ˜: {stats['calls']}íšŒ\n")
                f.write(f"  ì…ë ¥ í† í°: {stats['input_tokens']:,}ê°œ\n")
                f.write(f"  ì¶œë ¥ í† í°: {stats['output_tokens']:,}ê°œ\n")
                f.write(f"  ë¹„ìš©: ${stats['cost']:.4f} USD\n\n")
            
            # í˜¸ì¶œ ìœ í˜•ë³„ í†µê³„
            type_stats = {}
            for log in self.usage_log:
                call_type = log['call_type']
                if call_type not in type_stats:
                    type_stats[call_type] = {'calls': 0, 'cost': 0.0}
                type_stats[call_type]['calls'] += 1
                type_stats[call_type]['cost'] += log['total_cost_usd']
            
            f.write("í˜¸ì¶œ ìœ í˜•ë³„ í†µê³„:\n")
            f.write("-" * 50 + "\n")
            for call_type, stats in type_stats.items():
                f.write(f"{call_type}: {stats['calls']}íšŒ, ${stats['cost']:.4f} USD\n")
            
            # ìƒì„¸ ë¡œê·¸
            f.write("\n" + "=" * 80 + "\n")
            f.write("ìƒì„¸ API í˜¸ì¶œ ë¡œê·¸:\n")
            f.write("=" * 80 + "\n")
            for i, log in enumerate(self.usage_log, 1):
                f.write(f"[{i}] {log['timestamp']}\n")
                f.write(f"    ëª¨ë¸: {log['model']}\n")
                f.write(f"    ìœ í˜•: {log['call_type']}\n")
                f.write(f"    í† í°: {log['input_tokens']} â†’ {log['output_tokens']}\n")
                f.write(f"    ë¹„ìš©: ${log['total_cost_usd']:.6f} USD\n\n")
        
        print(f"API ì‚¬ìš©ëŸ‰ ë¦¬í¬íŠ¸ ì €ì¥: {filename}")
        return filename

class BookRecommendationSystem:
    def __init__(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        # API í‚¤ ì„¤ì •
        self.gemini_api_key = os.getenv('GOOGLE_API_KEY')
        self.naver_client_id = os.getenv('NAVER_CLIENT_ID')
        self.naver_client_secret = os.getenv('NAVER_CLIENT_SECRET')
        
        if not self.gemini_api_key:
            raise ValueError("GOOGLE_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if not self.naver_client_id or not self.naver_client_secret:
            raise ValueError("ë„¤ì´ë²„ API í‚¤ê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # Gemini API ì„¤ì •
        genai.configure(api_key=self.gemini_api_key)
        self.model = genai.GenerativeModel('gemini-1.5-pro')  # ì¢…í•© ë¶„ì„ìš© ëª¨ë¸
        
        # API ì‚¬ìš©ëŸ‰ ì¶”ì ê¸°
        self.api_tracker = APIUsageTracker()
        
        # ê³ ë“±í•™ìƒ ì í•©ë„ í‚¤ì›Œë“œ
        self.suitable_keywords = [
            'ê³ ë“±í•™ìƒ', 'ì²­ì†Œë…„', 'ì…ë¬¸', 'ê¸°ì´ˆ', 'ì‰¬ìš´', 'ì´í•´í•˜ê¸°', 'ê°œë¡ ', 
            'êµì–‘', 'í•™ìŠµ', 'ê³µë¶€', 'ìˆ˜í—˜ìƒ', 'ëŒ€í•™', 'ì§„ë¡œ', 'ë¯¸ë˜'
        ]
        self.unsuitable_keywords = [
            'ëŒ€í•™ì›', 'ë°•ì‚¬', 'ì„ì‚¬', 'ì „ë¬¸ê°€', 'ê³ ê¸‰', 'ì‹¬í™”', 'ì—°êµ¬ì', 
            'í•™ìˆ ë…¼ë¬¸', 'ì´ë¡ ì„œ', 'ì „ê³µì„œì '
        ]
        
        self.processed_count = 0
        self.total_count = 0
        
    def extract_keywords_with_gemini(self, topic: str) -> Tuple[List[str], Dict]:
        """Geminië¥¼ ì‚¬ìš©í•˜ì—¬ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì¶”ê°€ ì •ë³´ ìƒì„±"""
        prompt = f"""
ê³ ë“±í•™ìƒ íƒêµ¬ì£¼ì œ: "{topic}"

ì´ íƒêµ¬ì£¼ì œë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:

{{
    "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3", "í‚¤ì›Œë“œ4", "í‚¤ì›Œë“œ5", "í‚¤ì›Œë“œ6", "í‚¤ì›Œë“œ7"],
    "academic_field": "ì£¼ìš” í•™ë¬¸ë¶„ì•¼",
    "difficulty_level": "ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì—ì„œì˜ ë‚œì´ë„ (ìƒ/ì¤‘/í•˜)",
    "additional_keywords": ["ì¶”ê°€ê²€ìƒ‰ìš© í‚¤ì›Œë“œ1", "ì¶”ê°€ê²€ìƒ‰ìš© í‚¤ì›Œë“œ2"],
    "book_types": ["ê´€ë ¨ ë„ì„œ ìœ í˜•1", "ê´€ë ¨ ë„ì„œ ìœ í˜•2"],
    "cautions": "ë„ì„œ ì„ ì • ì‹œ ì£¼ì˜ì‚¬í•­"
}}

ì£¼ìš” ìš”êµ¬ì‚¬í•­:
1. keywords: ë„ì„œ ê²€ìƒ‰ì— íš¨ê³¼ì ì¸ 5-7ê°œ í‚¤ì›Œë“œ (í•œêµ­ì–´, êµ¬ì²´ì ì´ê³  ê²€ìƒ‰ ê°€ëŠ¥í•œ ìš©ì–´)
2. academic_field: ë¬¼ë¦¬í•™, í™”í•™, ìƒë¬¼í•™, ìˆ˜í•™, ì‚¬íšŒê³¼í•™, ì¸ë¬¸í•™ ë“±
3. difficulty_level: ê³ ë“±í•™ìƒì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ì¸ì§€ í‰ê°€
4. additional_keywords: ë³´ì™„ì  ê²€ìƒ‰ìš© í‚¤ì›Œë“œ 1-2ê°œ
5. book_types: ì´ë¡ ì„œ, ì‹¤í—˜ì„œ, êµì–‘ì„œ, ì…ë¬¸ì„œ ë“± ì ì ˆí•œ ë„ì„œ ìœ í˜•
6. cautions: ë„ˆë¬´ ì–´ë µê±°ë‚˜ ë¶€ì ì ˆí•œ ë„ì„œë¥¼ í”¼í•˜ê¸° ìœ„í•œ ì£¼ì˜ì‚¬í•­

ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
"""
        
        try:
            print(f"Gemini APIë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘: {topic[:50]}...")
            response = self.model.generate_content(prompt)
            
            # API ì‚¬ìš©ëŸ‰ ë¡œê¹…
            self.api_tracker.log_api_call(
                'gemini-1.5-pro', prompt, response.text, 'keyword_extraction'
            )
            
            # JSON íŒŒì‹±
            json_text = response.text.strip()
            if json_text.startswith('```json'):
                json_text = json_text[7:-3].strip()
            elif json_text.startswith('```'):
                json_text = json_text[3:-3].strip()
                
            result = json.loads(json_text)
            
            return result.get('keywords', []), result
            
        except Exception as e:
            print(f"Gemini API ì˜¤ë¥˜: {e}")
            print(f"  í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨")
            return [], {
                'keywords': [],
                'academic_field': 'ë¯¸ë¶„ë¥˜',
                'difficulty_level': 'ì¤‘',
                'additional_keywords': [],
                'book_types': [],
                'cautions': 'API ì˜¤ë¥˜ë¡œ ì¸í•œ ì²˜ë¦¬ ì‹¤íŒ¨'
            }
    
    def search_books_naver(self, keywords: List[str], max_per_keyword: int = 10) -> List[Dict]:
        """ë„¤ì´ë²„ ë„ì„œ APIë¡œ ë„ì„œ ê²€ìƒ‰"""
        all_books = []
        
        for keyword in keywords[:3]:  # ìƒìœ„ 3ê°œ í‚¤ì›Œë“œë§Œ ì‚¬ìš©
            try:
                print(f"  ë„¤ì´ë²„ API ê²€ìƒ‰: {keyword}")
                
                headers = {
                    'X-Naver-Client-Id': self.naver_client_id,
                    'X-Naver-Client-Secret': self.naver_client_secret,
                }
                
                params = {
                    'query': keyword,
                    'display': max_per_keyword,
                    'sort': 'sim'  # ì •í™•ë„ìˆœ
                }
                
                response = requests.get(
                    'https://openapi.naver.com/v1/search/book.json',
                    headers=headers,
                    params=params,
                    timeout=10
                )
                
                if response.status_code == 200:
                    data = response.json()
                    books = data.get('items', [])
                    
                    for book in books:
                        if book.get('isbn'):
                            all_books.append({
                                'title': re.sub(r'<[^>]+>', '', book.get('title', '')),
                                'author': re.sub(r'<[^>]+>', '', book.get('author', '')),
                                'publisher': book.get('publisher', ''),
                                'pubdate': book.get('pubdate', ''),
                                'isbn': book.get('isbn', '').split()[-1],  # 13ìë¦¬ ISBN ì‚¬ìš©
                                'description': re.sub(r'<[^>]+>', '', book.get('description', '')),
                                'search_keyword': keyword
                            })
                
                time.sleep(0.1)  # API í˜¸ì¶œ ê°„ê²©
                
            except Exception as e:
                print(f"  ë„¤ì´ë²„ API ì˜¤ë¥˜ ({keyword}): {e}")
                continue
        
        # ISBN ê¸°ì¤€ ì¤‘ë³µ ì œê±°
        unique_books = {}
        for book in all_books:
            isbn = book['isbn']
            if isbn and isbn not in unique_books:
                unique_books[isbn] = book
        
        return list(unique_books.values())
    
    def verify_books_with_llm(self, books: List[Dict], topic: str, topic_info: Dict) -> List[Dict]:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ë„ì„œ ì í•©ì„± ê²€ì¦ ë° ì ìˆ˜ ê³„ì‚°"""
        if not books:
            return []
        
        # ìƒìœ„ 15ê¶Œë§Œ ê²€ì¦ (API ë¹„ìš© ì ˆì•½)
        books_to_verify = books[:15]
        
        book_list = []
        for i, book in enumerate(books_to_verify, 1):
            book_info = f"{i}. ì œëª©: {book['title']}\n"
            book_info += f"   ì €ì: {book['author']}\n"
            book_info += f"   ì¶œíŒì‚¬: {book['publisher']}\n"
            book_info += f"   ì¶œê°„ë…„ë„: {book['pubdate']}\n"
            book_info += f"   ì„¤ëª…: {book['description'][:200]}...\n"
            book_list.append(book_info)
        
        prompt = f"""
ê³ ë“±í•™ìƒ íƒêµ¬ì£¼ì œ: "{topic}"
ì£¼ì œ ë¶„ì„ ì •ë³´:
- í•™ë¬¸ë¶„ì•¼: {topic_info.get('academic_field', 'ë¯¸ë¶„ë¥˜')}
- ë‚œì´ë„: {topic_info.get('difficulty_level', 'ì¤‘')}
- ë„ì„œ ìœ í˜•: {', '.join(topic_info.get('book_types', ['êµì–‘ì„œ']))}
- ì£¼ì˜ì‚¬í•­: {topic_info.get('cautions', 'ì—†ìŒ')}

ê²€ì¦í•  ë„ì„œ ëª©ë¡:
{chr(10).join(book_list)}

ê° ë„ì„œì— ëŒ€í•´ ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ ì ìˆ˜ë¥¼ ë§¤ê¸°ê³  JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:

{{
    "book_scores": [
        {{
            "book_number": 1,
            "relevance_score": 30,
            "appropriateness_score": 25,
            "reliability_score": 20,
            "recency_score": 15,
            "accessibility_score": 10,
            "total_score": 100,
            "recommendation_reason": "250-300ìì˜ ìƒì„¸í•œ ì¶”ì²œ ì´ìœ "
        }},
        // ... ë‹¤ë¥¸ ë„ì„œë“¤
    ]
}}

ì ìˆ˜ ê¸°ì¤€:
1. relevance_score (ì—°ê´€ì„±, 0-30ì ): íƒêµ¬ì£¼ì œì™€ì˜ ì§ì ‘ì  ê´€ë ¨ì„±
2. appropriateness_score (ì í•©ì„±, 0-25ì ): ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì—ì˜ ì í•©ì„±
3. reliability_score (ì‹ ë¢°ì„±, 0-20ì ): ì €ì/ì¶œíŒì‚¬ì˜ ê¶Œìœ„ì„±, ë‚´ìš©ì˜ ì •í™•ì„±
4. recency_score (ìµœì‹ ì„±, 0-15ì ): ì¶œê°„ë…„ë„ì˜ ìµœì‹ ì„± (2020ë…„ ì´í›„ ë§Œì )
5. accessibility_score (ì ‘ê·¼ì„±, 0-10ì ): êµ¬ë§¤/ëŒ€ì¶œì˜ ìš©ì´ì„±, ì½ê¸° ë‚œì´ë„

recommendation_reasonì€ ë°˜ë“œì‹œ 250-300ìë¡œ ì‘ì„±í•˜ë©°, ë‹¤ìŒì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
- íƒêµ¬ì£¼ì œì™€ì˜ êµ¬ì²´ì  ì—°ê´€ì„±
- ê³ ë“±í•™ìƒì—ê²Œ ì í•©í•œ ì´ìœ 
- ì´ ì±…ì„ í†µí•´ ì–»ì„ ìˆ˜ ìˆëŠ” êµ¬ì²´ì  ì§€ì‹/ì¸ì‚¬ì´íŠ¸
- íƒêµ¬ í™œë™ì— ë„ì›€ì´ ë˜ëŠ” ë°©ë²•

ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
"""
        
        try:
            print("  LLMìœ¼ë¡œ ë„ì„œ ê²€ì¦ ì¤‘...")
            response = self.model.generate_content(prompt)
            
            # API ì‚¬ìš©ëŸ‰ ë¡œê¹…
            self.api_tracker.log_api_call(
                'gemini-1.5-pro', prompt, response.text, 'book_verification'
            )
            
            json_text = response.text.strip()
            if json_text.startswith('```json'):
                json_text = json_text[7:-3].strip()
            elif json_text.startswith('```'):
                json_text = json_text[3:-3].strip()
            
            result = json.loads(json_text)
            book_scores = result.get('book_scores', [])
            
            # ì ìˆ˜ë¥¼ ì›ë³¸ ë„ì„œ ì •ë³´ì— ì¶”ê°€
            verified_books = []
            for score_info in book_scores:
                book_num = score_info.get('book_number', 1) - 1
                if 0 <= book_num < len(books_to_verify):
                    book = books_to_verify[book_num].copy()
                    book.update({
                        'llm_total_score': score_info.get('total_score', 0),
                        'llm_relevance': score_info.get('relevance_score', 0),
                        'llm_appropriateness': score_info.get('appropriateness_score', 0),
                        'llm_reliability': score_info.get('reliability_score', 0),
                        'llm_recency': score_info.get('recency_score', 0),
                        'llm_accessibility': score_info.get('accessibility_score', 0),
                        'recommendation_reason': score_info.get('recommendation_reason', 'ì¶”ì²œ ì´ìœ ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
                    })
                    verified_books.append(book)
            
            return sorted(verified_books, key=lambda x: x.get('llm_total_score', 0), reverse=True)
            
        except Exception as e:
            print(f"  LLM ê²€ì¦ ì˜¤ë¥˜: {e}")
            return []
    
    def process_single_topic(self, topic: str) -> Dict:
        """ë‹¨ì¼ íƒêµ¬ì£¼ì œ ì²˜ë¦¬"""
        self.processed_count += 1
        print(f"\n[{self.processed_count}/{self.total_count}] ì²˜ë¦¬ ì¤‘: {topic}")
        
        try:
            # 1ë‹¨ê³„: Geminië¡œ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ë¶„ì„
            keywords, topic_info = self.extract_keywords_with_gemini(topic)
            print(f"  ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")
            print(f"  í•™ë¬¸ë¶„ì•¼: {topic_info.get('academic_field', 'ë¯¸ë¶„ë¥˜')}")
            
            # 2ë‹¨ê³„: ë„¤ì´ë²„ APIë¡œ ë„ì„œ ê²€ìƒ‰
            books = self.search_books_naver(keywords)
            print(f"  ê²€ìƒ‰ëœ ë„ì„œ: {len(books)}ê¶Œ")
            
            # 3ë‹¨ê³„: LLMìœ¼ë¡œ ë„ì„œ ê²€ì¦ ë° ì ìˆ˜ ê³„ì‚°
            verified_books = self.verify_books_with_llm(books, topic, topic_info)
            
            # ìƒìœ„ 2ê¶Œ ì„ ì •
            top_books = verified_books[:2]
            
            result = {
                'topic': topic,
                'keywords': keywords,
                'topic_analysis': topic_info,
                'total_books_found': len(books),
                'verified_books_count': len(verified_books),
                'recommended_books': []
            }
            
            for i, book in enumerate(top_books, 1):
                result['recommended_books'].append({
                    'rank': i,
                    'title': book['title'],
                    'author': book['author'],
                    'publisher': book['publisher'],
                    'publication_date': book['pubdate'],
                    'isbn': book['isbn'],
                    'description': book['description'][:200] + '...' if len(book['description']) > 200 else book['description'],
                    'total_score': book.get('llm_total_score', 0),
                    'score_details': {
                        'relevance': book.get('llm_relevance', 0),
                        'appropriateness': book.get('llm_appropriateness', 0),
                        'reliability': book.get('llm_reliability', 0),
                        'recency': book.get('llm_recency', 0),
                        'accessibility': book.get('llm_accessibility', 0)
                    },
                    'recommendation_reason': book.get('recommendation_reason', ''),
                    'search_keyword': book.get('search_keyword', '')
                })
            
            print(f"  ì¶”ì²œ ë„ì„œ: {len(top_books)}ê¶Œ")
            return result
            
        except Exception as e:
            print(f"  ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return {
                'topic': topic,
                'keywords': [],
                'topic_analysis': {'error': str(e)},
                'total_books_found': 0,
                'verified_books_count': 0,
                'recommended_books': []
            }
    
    def process_excel_file(self, input_file: str) -> Dict:
        """Excel íŒŒì¼ì˜ ëª¨ë“  íƒêµ¬ì£¼ì œ ì²˜ë¦¬"""
        print(f"Excel íŒŒì¼ ë¡œë“œ ì¤‘: {input_file}")
        
        # Excel íŒŒì¼ ì½ê¸°
        df = pd.read_excel(input_file)
        
        if 'task' not in df.columns:
            raise ValueError("Excel íŒŒì¼ì— 'task' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        topics = df['task'].dropna().tolist()
        self.total_count = len(topics)
        
        print(f"ì´ {self.total_count}ê°œ íƒêµ¬ì£¼ì œ ì²˜ë¦¬ ì‹œì‘")
        print("=" * 80)
        
        start_time = time.time()
        results = []
        keywords_list = []
        academic_fields = []
        
        for topic in topics:
            result = self.process_single_topic(topic)
            results.append(result)
            
            # keywords ì»¬ëŸ¼ìš© ë°ì´í„° ìˆ˜ì§‘
            keywords_list.append(', '.join(result['keywords']))
            academic_fields.append(result['topic_analysis'].get('academic_field', 'ë¯¸ë¶„ë¥˜'))
            
            # ì§„í–‰ë¥  í‘œì‹œ
            progress = (self.processed_count / self.total_count) * 100
            print(f"  ì§„í–‰ë¥ : {progress:.1f}%")
            
            # API í˜¸ì¶œ ê°„ê²© (1.5-pro ëª¨ë¸ì´ë¯€ë¡œ ë” ì§§ì€ ê°„ê²©)
            time.sleep(0.5)
        
        processing_time = time.time() - start_time
        
        # Excel íŒŒì¼ì— keywords ì»¬ëŸ¼ ì¶”ê°€
        df['keywords'] = keywords_list
        df['academic_field'] = academic_fields
        
        # í†µê³„ ê³„ì‚°
        field_counts = Counter(academic_fields)
        avg_books_per_topic = sum(r['total_books_found'] for r in results) / len(results) if results else 0
        
        return {
            'total_topics': len(topics),
            'results': results,
            'statistics': {
                'academic_fields': dict(field_counts),
                'average_books_per_topic': round(avg_books_per_topic, 1),
                'total_processing_time': f"{processing_time:.1f}ì´ˆ",
                'api_cost_usd': round(self.api_tracker.total_cost, 4),
                'api_cost_krw': round(self.api_tracker.total_cost * 1300, 0),
                'api_calls_total': len(self.api_tracker.usage_log),
                'cost_per_topic_usd': round(self.api_tracker.total_cost / len(topics) if topics else 0, 4)
            },
            'updated_dataframe': df  # JSONì—ì„œëŠ” ì œì™¸, Excelë§Œ ì €ì¥
        }

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 80)
    print("ê³ ë“±í•™ìƒ íƒêµ¬ì£¼ì œ ë„ì„œ ì¶”ì²œ ì‹œìŠ¤í…œ (í†µí•© ë²„ì „)")
    print("- Gemini 1.5 Pro API ì‚¬ìš© (ìµœì  ì„±ëŠ¥)")
    print("- API ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ì¶”ì  ê¸°ëŠ¥")
    print("- Python 3.11 í˜¸í™˜")
    print("=" * 80)
    
    try:
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        system = BookRecommendationSystem()
        
        # Excel íŒŒì¼ ì²˜ë¦¬
        input_file = '../ì›ì²œíŒŒì¼/ì£¼ì œí…ŒìŠ¤íŠ¸_50.xlsx'
        if not os.path.exists(input_file):
            raise FileNotFoundError(f"{input_file} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        start_time = time.time()
        final_results = system.process_excel_file(input_file)
        processing_time = time.time() - start_time
        
        # ê²°ê³¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # JSON ê²°ê³¼ ì €ì¥ (DataFrame ì œì™¸)
        json_filename = f'../ê²°ê³¼íŒŒì¼/book_recommendations_{timestamp}.json'
        json_data = {
            'total_topics': final_results['total_topics'],
            'results': final_results['results'],
            'statistics': final_results['statistics']
        }
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        
        # Excel ê²°ê³¼ ì €ì¥ (keywords ì»¬ëŸ¼ ì¶”ê°€ë¨)
        excel_filename = f'../ê²°ê³¼íŒŒì¼/final_book_recommendations_{timestamp}.xlsx'
        final_results['updated_dataframe'].to_excel(excel_filename, index=False)
        
        # API ì‚¬ìš©ëŸ‰ ë¦¬í¬íŠ¸ ì €ì¥
        api_report_filename = system.api_tracker.save_usage_report(f'../ê²°ê³¼íŒŒì¼/api_usage_report_{timestamp}.txt')
        
        # ìµœì¢… ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 80)
        print("ì²˜ë¦¬ ì™„ë£Œ!")
        print("=" * 80)
        stats = final_results['statistics']
        print(f"ì´ ì²˜ë¦¬ ì‹œê°„: {stats['total_processing_time']}")
        print(f"ì²˜ë¦¬ëœ íƒêµ¬ì£¼ì œ: {final_results['total_topics']}ê°œ")
        print(f"í‰ê·  ë„ì„œ ë°œê²¬: {stats['average_books_per_topic']}ê¶Œ/ì£¼ì œ")
        
        print(f"\nğŸ’° API ë¹„ìš© ì •ë³´:")
        print(f"  ì´ API í˜¸ì¶œ: {stats['api_calls_total']}íšŒ")
        print(f"  ì˜ˆìƒ ì´ ë¹„ìš©: ${stats['api_cost_usd']} USD (â‚©{stats['api_cost_krw']:,})")
        print(f"  ì£¼ì œë‹¹ í‰ê·  ë¹„ìš©: ${stats['cost_per_topic_usd']} USD")
        
        print(f"\nğŸ“Š í•™ë¬¸ë¶„ì•¼ë³„ ë¶„í¬:")
        for field, count in stats['academic_fields'].items():
            print(f"  - {field}: {count}ê°œ")
        
        print(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
        print(f"  - JSON ê²°ê³¼: {json_filename}")
        print(f"  - Excel ê²°ê³¼: {excel_filename}")
        print(f"  - API ì‚¬ìš©ëŸ‰ ë¦¬í¬íŠ¸: {api_report_filename}")
        
        # ìƒ˜í”Œ ê²°ê³¼ ì¶œë ¥
        if final_results['results']:
            sample = final_results['results'][0]
            print(f"\nğŸ“š ìƒ˜í”Œ ê²°ê³¼ ('{sample['topic'][:30]}...'):")
            print(f"  í‚¤ì›Œë“œ: {', '.join(sample['keywords'])}")
            print(f"  í•™ë¬¸ë¶„ì•¼: {sample['topic_analysis'].get('academic_field', 'ë¯¸ë¶„ë¥˜')}")
            
            if sample['recommended_books']:
                book = sample['recommended_books'][0]
                print(f"  ì¶”ì²œë„ì„œ 1ìœ„: {book['title']} (ì ìˆ˜: {book['total_score']}ì )")
                print(f"  ISBN: {book['isbn']}")
                print(f"  ì¶”ì²œì´ìœ : {book['recommendation_reason'][:100]}...")
        
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 